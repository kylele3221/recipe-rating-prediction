{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recipe Rating Prediction\n",
    "\n",
    "**Name(s)**: Andrew Kim, Kyle Le\n",
    "\n",
    "**Website Link**: [(Recipe Rating Prediction)](https://kylele3221.github.io/recipe-rating-prediction/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.652554Z",
     "start_time": "2019-10-31T23:36:27.180520Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "import plotly.express as px\n",
    "pd.options.plotting.backend = 'plotly'\n",
    "\n",
    "from dsc80_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Data\n",
    "\n",
    "There are two data files, RAW_recipes.csv and interactions.csv, that will be referred to as the recipes and interactions data sets respectively.  Both data sets are scraped off of food.com."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Cleaning and Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.657068Z",
     "start_time": "2019-10-31T23:36:28.654650Z"
    }
   },
   "outputs": [],
   "source": [
    "recipes = pd.read_csv(\"RAW_recipes.csv\")\n",
    "ratings = pd.read_csv(\"interactions.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a function to convert the nutrition column from a string into a list and apply it\n",
    "def str_to_list(s):\n",
    "    s = s.strip()[1:-1]\n",
    "    if not s:\n",
    "        return []\n",
    "    return [float(item.strip()) for item in s.split(\",\")]\n",
    "\n",
    "recipes[\"nutrition\"] = recipes[\"nutrition\"].apply(str_to_list)\n",
    "\n",
    "# Split the nutrition column into each of its nutritional components\n",
    "nutrition_columns = [\n",
    "    \"calories\",\n",
    "    \"total fat\",\n",
    "    \"sugar\",\n",
    "    \"sodium\",\n",
    "    \"protein\",\n",
    "    \"saturated fat\",\n",
    "    \"carbohydrates\"\n",
    "]\n",
    "temp_df = pd.DataFrame(recipes[\"nutrition\"].to_list(), columns=nutrition_columns)\n",
    "recipes = recipes.drop(columns=[\"nutrition\"])\n",
    "recipes = pd.concat([recipes, temp_df], axis=1)\n",
    "\n",
    "# Merge data frames\n",
    "merged_df = recipes.merge(ratings, left_on='id', right_on='recipe_id', how='left')\n",
    "df = merged_df\n",
    "\n",
    "# Drop unncessary columns\n",
    "df = df.drop(columns=['name', 'minutes', 'contributor_id', 'submitted', 'tags',\n",
    "       'n_steps', 'steps', 'description', 'ingredients', 'n_ingredients',\n",
    "       'user_id', 'recipe_id', 'date', 'review'])\n",
    "\n",
    "\n",
    "# Get the average rating for each recipe\n",
    "df = df.groupby('id').agg({\n",
    "    'calories': 'first',\n",
    "    'total fat': 'first',\n",
    "    'sugar': 'first',\n",
    "    'sodium': 'first',\n",
    "    'protein': 'first',\n",
    "    'saturated fat': 'first',\n",
    "    'carbohydrates': 'first',\n",
    "    'rating': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "df = df.rename(columns={'rating': 'average_rating'})\n",
    "\n",
    "# 0 ratings to np.nan\n",
    "df['average_rating'] = df['average_rating'].replace(0, np.nan)\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate Analysis\n",
    "\n",
    "This section presents a univariate analysis to explore the relationship between product ratings and various nutrition facts, such as calories, fat, and protein content. The code summarizes the distribution of ratings across different levels of each nutritional variable, often visualizing these patterns with plots or summary statistics. By examining these relationships, we aim to identify any trends or associations, such as whether items with certain nutritional profiles tend to receive higher or lower ratings. This analysis helps to uncover potential factors that may influence how products are rated by consumers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univariate analysis for each rating.  Shows counts of eaching rating\n",
    "rating_counts = df['average_rating'].value_counts().sort_index().reset_index()\n",
    "rating_counts.columns = ['average_rating', 'count']\n",
    "\n",
    "# Create a bar chart\n",
    "fig = px.bar(\n",
    "    rating_counts,\n",
    "    x='average_rating', y='count',\n",
    "    labels={'average_rating': 'Average Rating', 'count': 'Number of Ratings'},\n",
    "    title='Distribution of Recipe Ratings'\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "\n",
    "\n",
    "# Univariate analysis for each nutritional component in histograms.  Shows counts of each component\n",
    "nutrition_columns = [\n",
    "    \"calories\", \"total fat\", \"sugar\", \"sodium\",\n",
    "    \"protein\", \"saturated fat\", \"carbohydrates\"\n",
    "]\n",
    "\n",
    "# Set the maximum value for each nutritional component for the x-axis\n",
    "x_max = {\n",
    "    \"calories\": 2500,\n",
    "    \"total fat\": 600,\n",
    "    \"sugar\": 2000,\n",
    "    \"sodium\": 2000,\n",
    "    \"protein\": 300,\n",
    "    \"saturated fat\": 500,\n",
    "    \"carbohydrates\": 300\n",
    "}\n",
    "\n",
    "# Create histograms for each nutritional component\n",
    "for col in nutrition_columns:\n",
    "    fig = px.histogram(\n",
    "        df,\n",
    "        x=col,\n",
    "        nbins=50,\n",
    "        title=f'Distribution of {col.title()}',\n",
    "        labels={col: col.title()},\n",
    "\n",
    "        # To help with showing most of the data, hides outliers\n",
    "        range_x=[0, x_max[col]]\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bivariate Analysis\n",
    "\n",
    "In this section, we conduct a bivariate analysis to investigate how product ratings relate to specific nutrition facts, such as calories, fat, or protein. The code examines the association between ratings and each nutritional variable by comparing the distribution of ratings across different levels or categories of the nutrition fact. Visualization techniques (such as scatter plots or boxplots) and summary statistics are used to explore whether there is a systematic relationship such as higher ratings for lower-calorie items or vice versa. This analysis provides deeper insight into how multiple variables interact and can reveal potential patterns that might not be evident in univariate analyses.  Plotting all of the data points caused extreme lag so a random set of 5000 data points were chosen to represent the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutrients = [\n",
    "    \"calories\",\n",
    "    \"total fat\",\n",
    "    \"sugar\",\n",
    "    \"sodium\",\n",
    "    \"protein\",\n",
    "    \"saturated fat\",\n",
    "    \"carbohydrates\"\n",
    "]\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "df_sample = df.sample(n=5000, random_state=42) if len(df) > 5000 else df.copy()\n",
    "\n",
    "# Using graphs to visualize relationships\n",
    "for nutrient in nutrients:\n",
    "    # Plot the downsampled data\n",
    "    plt.scatter(df_sample['average_rating'], df_sample[nutrient],  alpha=0.2)\n",
    "    plt.xlabel('Rating')\n",
    "    plt.ylabel('Calories')\n",
    "    plt.title('Scatter plot of Calories vs Rating (Downsampled)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interesting Aggregates\n",
    "\n",
    "This section explores interesting aggregate statistics derived from the dataset, focusing on summary measures that reveal broader patterns or notable outliers. The code calculates group level metrics, such as the average rating within categories defined by nutrition facts. By aggregating the data in different ways, we can identify standout items, observe trends across groups, and highlight key insights that might be obscured at the individual level. These aggregates help to summarize the data and point to potential areas for further investigation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates bins of uniform width 500\n",
    "bin_width = 500\n",
    "max_cut = 2500\n",
    "\n",
    "cal_edges = np.arange(0, max_cut + bin_width, bin_width)\n",
    "\n",
    "# Cuts off any values above 2500\n",
    "df[\"calories_clipped\"] = df[\"calories\"].clip(upper=max_cut)\n",
    "\n",
    "# Equal bins\n",
    "df[\"calories_bin\"] = pd.cut(\n",
    "    df[\"calories_clipped\"],\n",
    "    bins=cal_edges,\n",
    "    include_lowest=True\n",
    ")\n",
    "\n",
    "# Compute mean rating per bin\n",
    "agg_cal = (\n",
    "    df\n",
    "    .groupby(\"calories_bin\", observed=True)[\"average_rating\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .dropna()\n",
    ")\n",
    "\n",
    "agg_cal[\"bin_str\"] = agg_cal[\"calories_bin\"] \\\n",
    "    .apply(lambda iv: f\"{int(iv.left)}–{int(iv.right)}\")\n",
    "\n",
    "fig = px.bar(\n",
    "    agg_cal,\n",
    "    x=\"bin_str\",\n",
    "    y=\"average_rating\",\n",
    "    title=\"Average Recipe Rating by Calories (Uniform 500 Cal Bins)\",\n",
    "    labels={\"bin_str\": \"Calories Range\", \"average_rating\": \"Average Rating\"}\n",
    ")\n",
    "fig.update_layout(\n",
    "    xaxis={\n",
    "        \"categoryorder\":\"array\",\n",
    "        \"categoryarray\": agg_cal[\"bin_str\"].tolist()\n",
    "    }\n",
    ")\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Assessment of Missingness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMAR Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolating NaN value rows\n",
    "nan_rows = df[df.isna().any(axis=1)]\n",
    "print(nan_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the dataset, all missing values occur in the average_rating column. Any 0s in this column with NaN values, under the assumption that a rating of 0 did not represent a real rating but rather a missing or unreported value. This means that the missingness in the average_rating column is directly related to the value itself specifically, the missingness occurs when the original value was 0.\n",
    "\n",
    "Since the probability of a value being missing is determined by its value, the missingness mechanism is NMAR. We cannot determine this just by analyzing the observed data. Instead, it requires understanding the data generating process and recognizing that missing ratings are systematically related to their values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missingness Dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "merged_df['has_rating'] = merged_df['rating'].notna().astype(int)\n",
    "merged_df['missing_review'] = merged_df['review'].isna()\n",
    "\n",
    "# Permutation test function\n",
    "def permutation_test(df, test_col, missing_indicator, n_permutations=1000):\n",
    "    temp_df = df.dropna(subset=[test_col])\n",
    "    one = temp_df[temp_df[missing_indicator]][test_col]\n",
    "    zero = temp_df[~temp_df[missing_indicator]][test_col]\n",
    "    observed_diff = one.mean() - zero.mean()\n",
    "    differences = []\n",
    "    for i in range(n_permutations):\n",
    "        shuffled = np.random.permutation(temp_df[missing_indicator])\n",
    "        difference = temp_df[test_col][shuffled].mean() - temp_df[test_col][~shuffled].mean()\n",
    "        differences.append(difference)\n",
    "    p_value = np.mean(np.abs(differences) >= np.abs(observed_diff))\n",
    "    return observed_diff, p_value, np.array(differences)\n",
    "\n",
    "obs_diff_rating, p_val_rating, differences_rating = permutation_test(merged_df, 'has_rating', 'missing_review')\n",
    "\n",
    "fig_perm = go.Figure()\n",
    "fig_perm.add_trace(go.Histogram(\n",
    "    x=differences_rating,\n",
    "    nbinsx=30,\n",
    "    name=\"Permutation Differences\",\n",
    "    opacity=0.7\n",
    "))\n",
    "fig_perm.add_vline(\n",
    "    x=obs_diff_rating,\n",
    "    line_dash=\"dash\",\n",
    "    line_color=\"red\",\n",
    "    annotation_text=\"Observed Diff\",\n",
    "    annotation_position=\"top right\"\n",
    ")\n",
    "fig_perm.update_layout(\n",
    "    title=\"Permutation Test Distribution for Rating Missingness\",\n",
    "    xaxis_title=\"Difference in Mean (has_rating: review missing - review present)\",\n",
    "    yaxis_title=\"Count\"\n",
    ")\n",
    "fig_perm.show()\n",
    "\n",
    "temp_df = merged_df.dropna(subset=['minutes'])\n",
    "fig_box = px.box(\n",
    "    temp_df,\n",
    "    x='missing_review',\n",
    "    y='minutes',\n",
    "    labels={'missing_review': 'Review Missing', 'minutes': 'Minutes'},\n",
    "    title='Distribution of Minutes by Review Missingness'\n",
    ")\n",
    "fig_box.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Permutation tests were conducted to analyze the dependency of missingness in the review column on both the presence of a rating and the preparation time. The observed difference in the probability of having a rating between rows with and without missing reviews was -0.02, with a p-value of 0.0000, indicating a statistically significant association. In contrast, the observed difference in the average preparation time was 33.56 minutes, with a p-value of 0.6610, suggesting no statistically significant association. These results provide evidence that the missingness in the review column is related to the presence of a rating, but not to the preparation time of the recipe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Null hypothesis (H₀): The average rating of low-calorie recipes is equal to the average rating of high-calorie recipes.\n",
    "\n",
    "Alternative hypothesis (H₁): The average rating of low-calorie recipes is not equal to the average rating of high-calorie recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.666489Z",
     "start_time": "2019-10-31T23:36:28.664381Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split the data into two groups based on calorie level and extract the average ratings\n",
    "low_cal = df[df['calories'] <= 500]['average_rating'].dropna()\n",
    "high_cal = df[df['calories'] > 500]['average_rating'].dropna()\n",
    "\n",
    "# Compute the observed difference in average rating between high- and low-calorie recipes\n",
    "observed_diff = high_cal.mean() - low_cal.mean()\n",
    "print(\"Observed difference:\", observed_diff)\n",
    "\n",
    "# Combine the two groups into one dataset\n",
    "combined = pd.concat([low_cal, high_cal])\n",
    "labels = ['low'] * len(low_cal) + ['high'] * len(high_cal)\n",
    "\n",
    "n_reps = 1000\n",
    "diffs = []\n",
    "\n",
    "# Run permutation test\n",
    "for _ in range(n_reps):\n",
    "    shuffled = np.random.permutation(labels)\n",
    "    group1 = combined[np.array(shuffled) == 'low']\n",
    "    group2 = combined[np.array(shuffled) == 'high']\n",
    "    diffs.append(group2.mean() - group1.mean())\n",
    "\n",
    "# Compute the p-value: proportion of permuted diffs as or more extreme than the observed\n",
    "p_val = np.mean(np.abs(diffs) >= np.abs(observed_diff))\n",
    "print(\"p-value:\", p_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Framing a Prediction Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.657068Z",
     "start_time": "2019-10-31T23:36:28.654650Z"
    }
   },
   "source": [
    "Prediction: Can we predict the average rating of a recipe based on its nutritional components? For the purposes of this project, we will use calories and sugar.\n",
    "\n",
    "Justification: This is a realistic prediction task because nutrition facts are known at the time a recipe is published, but user ratings are not. Predicting ratings could help surface highly rated recipes early on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.662099Z",
     "start_time": "2019-10-31T23:36:28.660016Z"
    }
   },
   "outputs": [],
   "source": [
    "df_clean = df[['calories', 'sugar', 'average_rating']].dropna()\n",
    "X = df_clean[['calories', 'sugar']]\n",
    "y = df_clean['average_rating']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "baseline_model = LinearRegression()\n",
    "baseline_model.fit(X_train, y_train)\n",
    "y_pred = baseline_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Baseline Model Mean Squared Error: {mse:.4f}')\n",
    "print('Intercept:', baseline_model.intercept_)\n",
    "print('Coefficients:', baseline_model.coef_)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linestyle='--')\n",
    "plt.xlabel('Actual Average Rating')\n",
    "plt.ylabel('Predicted Average Rating')\n",
    "plt.title('Baseline Model: Predicted vs. Actual Ratings')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.662099Z",
     "start_time": "2019-10-31T23:36:28.660016Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add engineered features to the train and test sets\n",
    "X_train_f = X_train.copy()\n",
    "X_test_f = X_test.copy()\n",
    "\n",
    "# Feature 1: Interaction between calories and sugar\n",
    "X_train_f['calories_x_sugar'] = X_train_f['calories'] * X_train_f['sugar']\n",
    "X_test_f['calories_x_sugar'] = X_test_f['calories'] * X_test_f['sugar']\n",
    "\n",
    "# Feature 2: Log-transformed calories\n",
    "X_train_f['log_calories'] = np.log1p(X_train_f['calories'])\n",
    "X_test_f['log_calories'] = np.log1p(X_test_f['calories'])\n",
    "\n",
    "# Fit a Ridge Regression by hand and grid search alpha\n",
    "feature_cols = ['calories', 'sugar', 'calories_x_sugar', 'log_calories']\n",
    "\n",
    "# Standardize features based on training data\n",
    "means = X_train_f[feature_cols].mean()\n",
    "stds = X_train_f[feature_cols].std()\n",
    "X_train_scaled = (X_train_f[feature_cols] - means) / stds\n",
    "X_test_scaled = (X_test_f[feature_cols] - means) / stds\n",
    "\n",
    "# Manual grid search for Ridge penalty\n",
    "alphas = [0.01, 0.1, 1, 10, 100]\n",
    "best_alpha = None\n",
    "best_mse = np.inf\n",
    "best_coefs = None\n",
    "best_intercept = None\n",
    "\n",
    "for i in alphas:\n",
    "    # Closed-form Ridge regression: w = (X^T X + alpha*I)^-1 X^T y\n",
    "    X_mat = np.hstack([np.ones((X_train_scaled.shape[0], 1)), X_train_scaled.values])\n",
    "    I = np.eye(X_mat.shape[1])\n",
    "    I[0, 0] = 0  # Don't regularize intercept\n",
    "    w = np.linalg.inv(X_mat.T @ X_mat + i * I) @ (X_mat.T @ y_train.values)\n",
    "    X_test_mat = np.hstack([np.ones((X_test_scaled.shape[0], 1)), X_test_scaled.values])\n",
    "    y_pred_final = X_test_mat @ w\n",
    "    mse = ((y_pred_final - y_test.values) ** 2).mean()\n",
    "    if mse < best_mse:\n",
    "        best_mse = mse\n",
    "        best_alpha = i\n",
    "        best_coefs = w[1:]\n",
    "        best_intercept = w[0]\n",
    "\n",
    "print(f'Final Model Mean Squared Error: {best_mse:.4f}')\n",
    "print(f'Best alpha (ridge penalty): {best_alpha}')\n",
    "print('Intercept:', best_intercept)\n",
    "print('Coefficients:', best_coefs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Fairness Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.666489Z",
     "start_time": "2019-10-31T23:36:28.664381Z"
    }
   },
   "outputs": [],
   "source": [
    "# 1) Reconstruct the \"calories\" array for each test-row so we can form the two groups\n",
    "cal_test = X_test_f['calories']\n",
    "cal_test\n",
    "\n",
    "# 2) Boolean masks on test set\n",
    "cutoff = 500\n",
    "is_low = cal_test <= cutoff\n",
    "is_high = cal_test > cutoff\n",
    "\n",
    "# 3) Extract true and predicted ratings for each group\n",
    "mask_low = is_low.values\n",
    "mask_high = is_high.values\n",
    "\n",
    "y_true_low = y_test.values[mask_low]\n",
    "y_true_high = y_test.values[mask_high]\n",
    "\n",
    "y_pred_low = y_pred_final[mask_low]\n",
    "y_pred_high = y_pred_final[mask_high]\n",
    "\n",
    "# Observed RMSE Difference\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((y_pred - y_true) ** 2))\n",
    "\n",
    "rmse_low = rmse(y_true_low, y_pred_low)\n",
    "rmse_high = rmse(y_true_high, y_pred_high)\n",
    "\n",
    "observed_diff = rmse_high - rmse_low\n",
    "observed_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Hypotheses for Fairness Analysis</h3>\n",
    "- Null Hypothesis (H0): RMSE(high) - RMSE(low) = 0\n",
    "\n",
    "- Alternative Hypothesis (H1): RMSE(high) - RMSE(low) > 0 \n",
    "    (could do double sided but the theme of this project has been that higher calories  may be worse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pool of Test-set Errors and Group Labels\n",
    "\n",
    "# 1) Compute squared errors for each test example\n",
    "errors = (y_pred_final - y_test.values) ** 2\n",
    "\n",
    "# 2) Create a label array: \"L\" for low-cal, \"H\" for high-cal\n",
    "labels = np.where(is_low, \"L\", \"H\")\n",
    "\n",
    "print(\"Number of low‐cal test rows: \", np.sum(labels == \"L\"))\n",
    "print(\"Number of high‐cal test rows:\", np.sum(labels == \"H\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permutation test\n",
    "\n",
    "n_reps = 1000\n",
    "perm_diffs = np.empty(n_reps)\n",
    "\n",
    "n_low = np.sum(labels == \"L\")\n",
    "n_high = np.sum(labels == \"H\")\n",
    "\n",
    "for i in range(n_reps):\n",
    "    permuted_labels = np.random.permutation(labels)\n",
    "    errors_L = errors[permuted_labels == \"L\"]\n",
    "    errors_H = errors[permuted_labels == \"H\"]\n",
    "    \n",
    "    rmse_L = np.sqrt(np.mean(errors_L))\n",
    "    rmse_H = np.sqrt(np.mean(errors_H))\n",
    "    \n",
    "    perm_diffs[i] = rmse_H - rmse_L\n",
    "\n",
    "p_val = np.mean(np.abs(perm_diffs) >= np.abs(observed_diff))\n",
    "print(f\"Permutation test p-value: {p_val:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>\n",
    "    Fairness Analysis Interpretation\n",
    "</h3>\n",
    "\n",
    "- Because our p value was 0.6220 which is greater than 0.05, we fail to reject the null. We did not find evidence of a difference. The model's error on high-calories vs. low-calorie recipes could plausibly be the same, up to random variation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
